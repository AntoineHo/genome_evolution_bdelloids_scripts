{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e56ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File parsing and data handling\n",
    "from pysam import VariantFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File handling\n",
    "import os\n",
    "\n",
    "# Data dumping\n",
    "import bz2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271017c9",
   "metadata": {},
   "source": [
    "### Useful informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6172ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LENGTHS OF CHROMOSOMES\n",
    "reference = \"/mnt/urbe2/disk3/Antoine/19-11-21_VariantCalling_ARC/input/reference.fa\"\n",
    "fai = \"/mnt/urbe2/disk3/Antoine/19-11-21_VariantCalling_ARC/input/reference.fa.fai\"\n",
    "lengths = {}\n",
    "for line in open(fai, 'r') :\n",
    "    s = line.strip().split()\n",
    "    lengths[s[0]] = int(s[1])\n",
    "    \n",
    "median_coverage = {\n",
    "    \"ancestor\": 341,\n",
    "    \"D2A1\": 47,\n",
    "    \"D2B3\": 264, # has a 50G\n",
    "    \"D2B3_50G\": 408,\n",
    "    \"D2C1\": 110, # has a 50G\n",
    "    \"D2C1_50G\": 137,\n",
    "    \"D2C3\": 106, # has a 50G\n",
    "    \"D2C3_50G\": 118,\n",
    "    \"D3A1\": 49,\n",
    "    \"D3A3\": 105,  # has a 50G\n",
    "    \"D3A3_50G\": 177,\n",
    "    \"D4A3\": 54,\n",
    "    \"D4B4\": 144, # has a 50G\n",
    "    \"D4B4_50G\":176,\n",
    "    \"D5B3\": 73,\n",
    "    \"D5C1\": 120, # has a 50G\n",
    "    \"D5C1_50G\": 127,\n",
    "    \"D5C3\": 156, # has a 50G\n",
    "    \"D5C3_50G\": 194,\n",
    "    \"H2A3\": 449,\n",
    "    \"H2B4\": 122, # has a 50G\n",
    "    \"H2B4_50G\": 27, # LOW COVERAGE SAMPLE\n",
    "    \"H2C3\": 148,\n",
    "    \"H3A4\": 90, # has a 50G\n",
    "    \"H3A4_50G\": 150,\n",
    "    \"H3C4\": 127, # has a 50G\n",
    "    \"H3C4_50G\": 111,\n",
    "    \"H4A4\": 409, # has a 50G\n",
    "    \"H4A4_50G\": 404,\n",
    "    \"H4C2\": 204,\n",
    "    \"H5A2\": 54, # has a 50G\n",
    "    \"H5A2_50G\": 63,\n",
    "    \"H5A3\": 202,\n",
    "    \"H5A4\": 126, # has a 50G\n",
    "    \"H5A4_50G\": 131,\n",
    "    \"H5C2\": 148, # has a 50G\n",
    "    \"H5C2_50G\": 165,\n",
    "    \n",
    "    \"30H_C3_E4\":  199,\n",
    "    \"30H_C3_E5\":  209,\n",
    "    \"30H_C36_E5\": 244,\n",
    "    \"30H_C48_E5\": 275,\n",
    "    \n",
    "    \"30D_C13_E3\": 259,\n",
    "    \"30D_C38_E4\": 193,\n",
    "    \"30D_C38_E5\": 236,\n",
    "    \"30D_C52_E5\": 208,\n",
    "    \n",
    "    \"P0_C9_E4\":   186,\n",
    "    \"P0_C9_E5\":   174,\n",
    "    \"P0_C27_E5\":  242,\n",
    "    \"P0_C40_E5\":  192,\n",
    "    \n",
    "    \"P100_C8_E3\": 413,\n",
    "    \"P100_C8_E4\": 431,\n",
    "    \"P100_C30_E3\":424,\n",
    "    \"P100_C30_E4\":490,\n",
    "    \n",
    "    \"P250_C8_E3\": 390,\n",
    "    \"P250_C8_E4\": 334,\n",
    "    \"P250_C17_E3\":354,\n",
    "    \"P250_C17_E4\":435,\n",
    "    \n",
    "    \"P500_C16_E4\":185,\n",
    "    \"P500_C16_E5\":187,\n",
    "    \"P500_C18_E3\":291,\n",
    "    \"P500_C30_E3\":275,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6c6e8-fac8-4d8c-99c8-0e10df2a7691",
   "metadata": {},
   "source": [
    "### Get informations about packages\n",
    "\n",
    "Should print:\n",
    "```raw\n",
    "2.3.1\n",
    "4.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7471696c-5f15-49db-add0-a9dd668b408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "print(pickle.format_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce2a7d0",
   "metadata": {},
   "source": [
    "### Parsing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31cbb169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_windows_coverage_information(cov, sample, lengths, median_coverage, num_bins=251) :\n",
    "    coverage = pd.read_csv(cov, sep=\"\\t\", compression=\"gzip\", usecols=range(3), names=[\"ref\", \"pos\", \"cov\"], header=None, skiprows=1,)\n",
    "    coverage = coverage.rename(columns={\"ref\":\"CHR\", \"pos\":\"POS\", \"cov\":\"COV\"})\n",
    "    coverage = coverage.assign(nCOV=coverage[\"COV\"].div(median_coverage[sample]))\n",
    "    \n",
    "    per_contig_dfs = {}\n",
    "    for ctg in lengths.keys() :\n",
    "        cdf = coverage.query(\"CHR == @ctg\")\n",
    "        bins = np.linspace(0, lengths[ctg], num_bins)\n",
    "        cdf = cdf.assign(BIN=pd.cut(cdf[\"POS\"], bins))\n",
    "        gdf = cdf.groupby(by=\"BIN\", observed=False).agg(\n",
    "            { \"POS\":[\"first\", \"last\", \"mean\"],\n",
    "              \"COV\":[\"mean\", \"std\", \"min\", \"max\"],\n",
    "              \"nCOV\":[\"mean\", \"std\", \"min\", \"max\"],\n",
    "            }\n",
    "        )\n",
    "        per_contig_dfs[ctg] = gdf\n",
    "    \n",
    "    with bz2.BZ2File(\"{}_COV_windows.pandas231.pickle40.pbz2\".format(sample), 'wb') as f:\n",
    "        pickle.dump(per_contig_dfs, f)\n",
    "\n",
    "def get_windows_AF_information(vcf, sample, lengths, num_bins=251) :\n",
    "    \n",
    "    dc = {\"CHR\":[], \"POS\":[], \"AF\":[]}\n",
    "    \n",
    "    # AF = max(AD)/sum(AD)\n",
    "    vcf_in = VariantFile(vcf)  # auto-detect input format\n",
    "    vcf_in.subset_samples([\"ancestor\", sample])\n",
    "    \n",
    "    for n, rec in enumerate(vcf_in) :\n",
    "        #if n == 500000 :\n",
    "        #    break\n",
    "        if n % 1000000 == 0 :\n",
    "            print(\"Elapsed records: {}\".format(n))\n",
    "            \n",
    "        dc[\"CHR\"].append(rec.chrom)\n",
    "        dc[\"POS\"].append(rec.pos)\n",
    "        \n",
    "        try :\n",
    "            anc_gt = list(rec.samples[\"ancestor\"][\"GT\"])\n",
    "            num_unknown = 0\n",
    "            for al in anc_gt :\n",
    "                if al is None :\n",
    "                    num_unknown += 1                    \n",
    "            if len(set(anc_gt)) == 1 :\n",
    "                af = None\n",
    "            elif len(anc_gt) - num_unknown < 2 :\n",
    "                af = None\n",
    "            else :\n",
    "                sample_ad = rec.samples[sample][\"AD\"] # sample_ad = (25, 10, 0, 0)\n",
    "                genotype_ad = [sample_ad[allele_index] for allele_index in anc_gt] # anc_gt = (0, 1)\n",
    "                # genotype_ad = (25,10)\n",
    "                if len(genotype_ad) > 1 :\n",
    "                    af = float(max(genotype_ad)/sum(genotype_ad))\n",
    "                else :\n",
    "                    af = None\n",
    "        except :\n",
    "            print(\"Warning: line {} = {}\".format(n, rec))\n",
    "            af = None\n",
    "            ad = None\n",
    "        \n",
    "        dc[\"AF\"].append(af)\n",
    "        \n",
    "    df = pd.DataFrame().from_dict(dc)\n",
    "    \n",
    "    per_contig_dfs = {}\n",
    "    \n",
    "    for ctg in lengths.keys() :\n",
    "        \n",
    "        cdf = df.query(\"CHR == @ctg\")\n",
    "        bins = np.linspace(0, lengths[ctg], num_bins)\n",
    "        cdf = cdf.assign(BIN=pd.cut(cdf[\"POS\"], bins))\n",
    "        gdf = cdf.groupby(by=\"BIN\", observed=False).agg(\n",
    "            {\"POS\":[\"first\", \"last\", \"mean\"], \"AF\":[\"mean\", \"std\"],}\n",
    "        )\n",
    "        per_contig_dfs[ctg] = gdf\n",
    "    \n",
    "    with bz2.BZ2File(\"{}_AF_windows.pandas231.pickle40.pbz2\".format(sample), 'wb') as f:\n",
    "        pickle.dump(per_contig_dfs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a885aa",
   "metadata": {},
   "source": [
    "# 1. Read all VCFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc42da93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GR_samples = ['ancestor', 'P100_C8_E4', '30H_C36_E5', 'P250_C8_E3', '30D_C52_E5', '30D_C38_E4', 'P500_C16_E5', 'P100_C30_E4', '30H_C3_E5', 'P0_C27_E5', 'P500_C16_E4', '30D_C13_E3', '30D_C38_E5', 'P0_C9_E5', '30H_C48_E5', 'P250_C17_E4', 'P0_C9_E4', '30H_C3_E4', 'P100_C8_E3', 'P250_C8_E4', 'P500_C30_E3', 'P250_C17_E3', 'P500_C18_E3', 'P0_C40_E5', 'P100_C30_E3']\n",
    "ME_samples = ['D5C1', 'D2C1', 'H4A4', 'D4B4_50G', 'H5A2', 'D3A3_50G', 'H3C4_50G', 'H5A2_50G', 'H5C2_50G', 'H3A4_50G', 'D4B4', 'H2C3', 'D5C1_50G', 'H5A4', 'H4A4_50G', 'H2A3', 'D2C3_50G', 'H2B4_50G', 'D3A3', 'D2B3', 'H3A4', 'D3A1', 'H5A3', 'D5B3', 'D5C3', 'D5C3_50G', 'D2C3', 'H4C2', 'H5A4_50G', 'D2C1_50G', 'H2B4', 'D4A3', 'H5C2', 'D2A1', 'D2B3_50G', 'H3C4']\n",
    "\n",
    "GR_bcf = \"/mnt/urbe2/disk3/Antoine/19-11-21_VariantCalling_ARC/jointgenotyping/merged.only_het.gets.bcf\"\n",
    "ME_bcf = \"/mnt/urbe2/disk3/Antoine/27-10-21_VariantCalling_MA/genotype_allsamples/merged.only_het.gets.bcf\"\n",
    "\n",
    "for sample in GR_samples :\n",
    "    print(\"Reading VCF for sample: {}...\".format(sample))\n",
    "    get_windows_AF_information(GR_bcf, sample, lengths)\n",
    "\n",
    "for sample in ME_samples :\n",
    "    print(\"Reading VCF for sample: {}...\".format(sample))\n",
    "    get_windows_AF_information(ME_bcf, sample, lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6ad76",
   "metadata": {},
   "source": [
    "# 2. Read all Coverages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d63fb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GR files: 25\n",
      "ME files: 37\n",
      "All files: 61\n"
     ]
    }
   ],
   "source": [
    "data_gr = os.listdir(\"/mnt/urbe2/disk3/Antoine/19-11-21_VariantCalling_ARC/coverage\")\n",
    "data_gr = [os.path.join(\"/mnt/urbe2/disk3/Antoine/19-11-21_VariantCalling_ARC/coverage\", f) for f in data_gr if f.endswith(\".cov.gz\")]\n",
    "\n",
    "data_me = os.listdir(\"/mnt/urbe2/disk3/Antoine/27-10-21_VariantCalling_MA/coverage/\")\n",
    "data_me = [os.path.join(\"/mnt/urbe2/disk3/Antoine/27-10-21_VariantCalling_MA/coverage/\", f) for f in data_me if f.endswith(\".cov.gz\")]\n",
    "\n",
    "samples_gr = {os.path.basename(filepath).split(\".\")[0]:filepath for filepath in data_gr}\n",
    "samples_me = {os.path.basename(filepath).split(\".\")[0]:filepath for filepath in data_me}\n",
    "\n",
    "print(\"GR files:\", len(samples_gr))\n",
    "print(\"ME files:\", len(samples_me))\n",
    "\n",
    "# Note: ancestor is read twice now, merging dict to avoid this\n",
    "all_samples = {k:v for k, v in samples_gr.items()}\n",
    "for k, v in samples_me.items() :\n",
    "    if k not in all_samples.keys() :\n",
    "        all_samples[k] = v\n",
    "\n",
    "print(\"All files:\", len(all_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66617a4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading COV for sample: P0_C9_E5...\n",
      "Reading COV for sample: P250_C8_E3...\n",
      "Reading COV for sample: 30D_C13_E3...\n",
      "Reading COV for sample: P100_C30_E4...\n",
      "Reading COV for sample: 30H_C3_E5...\n",
      "Reading COV for sample: P100_C30_E3...\n",
      "Reading COV for sample: P250_C17_E3...\n",
      "Reading COV for sample: 30D_C52_E5...\n",
      "Reading COV for sample: P500_C16_E4...\n",
      "Reading COV for sample: 30D_C38_E4...\n",
      "Reading COV for sample: 30H_C3_E4...\n",
      "Reading COV for sample: P250_C17_E4...\n",
      "Reading COV for sample: P0_C27_E5...\n",
      "Reading COV for sample: P500_C16_E5...\n",
      "Reading COV for sample: P0_C40_E5...\n",
      "Reading COV for sample: P500_C30_E3...\n",
      "Reading COV for sample: P100_C8_E3...\n",
      "Reading COV for sample: P100_C8_E4...\n",
      "Reading COV for sample: P250_C8_E4...\n",
      "Reading COV for sample: 30H_C48_E5...\n",
      "Reading COV for sample: P0_C9_E4...\n",
      "Reading COV for sample: ancestor...\n",
      "Reading COV for sample: 30H_C36_E5...\n",
      "Reading COV for sample: P500_C18_E3...\n",
      "Reading COV for sample: 30D_C38_E5...\n",
      "Reading COV for sample: D5C1...\n",
      "Reading COV for sample: H5A2...\n",
      "Reading COV for sample: D2C1_50G...\n",
      "Reading COV for sample: H2C3...\n",
      "Reading COV for sample: H2B4...\n",
      "Reading COV for sample: H4C2...\n",
      "Reading COV for sample: D3A3_50G...\n",
      "Reading COV for sample: H3C4...\n",
      "Reading COV for sample: D3A3...\n",
      "Reading COV for sample: H3C4_50G...\n",
      "Reading COV for sample: H2B4_50G...\n",
      "Reading COV for sample: H4A4_50G...\n",
      "Reading COV for sample: H5A4...\n",
      "Reading COV for sample: D5C3_50G...\n",
      "Reading COV for sample: H4A4...\n",
      "Reading COV for sample: H5A2_50G...\n",
      "Reading COV for sample: H3A4...\n",
      "Reading COV for sample: D2B3...\n",
      "Reading COV for sample: D5C1_50G...\n",
      "Reading COV for sample: D2B3_50G...\n",
      "Reading COV for sample: D2C3_50G...\n",
      "Reading COV for sample: D2C3...\n",
      "Reading COV for sample: H2A3...\n",
      "Reading COV for sample: D3A1...\n",
      "Reading COV for sample: H5C2...\n",
      "Reading COV for sample: H5A3...\n",
      "Reading COV for sample: D2C1...\n",
      "Reading COV for sample: H5A4_50G...\n",
      "Reading COV for sample: H5C2_50G...\n",
      "Reading COV for sample: D5C3...\n",
      "Reading COV for sample: D4A3...\n",
      "Reading COV for sample: D4B4_50G...\n",
      "Reading COV for sample: D4B4...\n",
      "Reading COV for sample: D2A1...\n",
      "Reading COV for sample: D5B3...\n",
      "Reading COV for sample: H3A4_50G...\n"
     ]
    }
   ],
   "source": [
    "for sample, coverage_file in all_samples.items() :\n",
    "    print(\"Reading COV for sample: {}...\".format(sample))\n",
    "    get_windows_coverage_information(coverage_file, sample, lengths, median_coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136dbfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
